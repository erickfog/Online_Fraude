{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f30d4b7d",
   "metadata": {},
   "source": [
    "# Desafio Engenharia de Dados Mobi2buy \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e192b3ea",
   "metadata": {},
   "source": [
    "## Planejamento da Solução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2ec46",
   "metadata": {},
   "source": [
    "    \n",
    "    O que entragar?\n",
    "        - código desenvolvido para a resolução do teste (arquivo em .ipynb ou executáve .py)\n",
    "        - instruções de execução da solução enviada\n",
    "        - os arquivos gerados pela execução do código\n",
    "    \n",
    "__________________________________________________________________________________________________________________\n",
    "        1. formatar uma saída do log em json contendo a lista de request apresentada no log, cada objeto dentro da lista deve conter as propriedades de uma entrada no log como remote_host, date, request, status_code, response_time, reffer, user_agent.\n",
    "        2. encontrar os 10 maiores tempos de resposta com sucesso do servidor na chamada GET/manual/ com a origem do tráfego (reffer) igual a \"http://localhost/svnview?repos=devel&rev=latest&root=SVNview/tmpl&list_revs=1\"\n",
    "        3. formatar uma saída em arquivo físico do access.log igual ao log original porém com a data em formato UNIX timestamp %Y-%m-%d %H:%M:%S e o IP convertido em uma string representando o valor do hash MD5 do remote I - \n",
    "        4.formatar uma saída em arquivo físico agrupando a soma total de requests por dia do ano \n",
    "        5. formatar uma saída em arquivo físico com endereços de IP únicos, um IP por linha, contidos no log com a última data de request realizado pelo remote IP\n",
    " _______________________________________________________________________________________________________________\n",
    "     \n",
    "     Como fazer? \n",
    "         Item 1: Construir uma função para ler os dados do arquivo de log, extrair os dados, colocar os dados dentro de uma lista em que cada objeto da lista é um json com a chave sendo um dos campos e o valor sendo um dos resultados do log. (arquivo final: log_data.json)\n",
    "         \n",
    "         Item 2: Escrever uma função a qual o seu parâmetro será os dados coletados no item anterior. Filtrar todos os campos com status_code=='200(sucesso) e com a origem do tráfego de rede igual ao valor pedido. arquivo final: (top_10_slowest_request.json)\n",
    "         \n",
    "         Item 3: Vamos utilizador os dados extraídos, fazer as converções necessárias e escrever em um arquivo final. Arquivo Final: (formatted_access.log)\n",
    "         \n",
    "         Item 4: Vamos utilizar os dados extraídos e construir uma lógica para agrupar os dias do anos fazendo a soma total. Podemos utilizar o pandas para agrupar, mas como já temos os dados dentro de um json, vamos utilizar if e else para fazer a soma. Arquivo final: (requests_per_day.json)\n",
    "         \n",
    "         Item 5: Vamos construir um código para filtrar os ips únicos, colocar um ip em cada linha e colocar ao lado a última data de request. Arquivo final: (unique_ips_with_last_dates.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95592e96",
   "metadata": {},
   "source": [
    "\n",
    "Arquivos de Saída: log_data.json, top_10_slowest_request.json,  requests_per_day.json e unique_ips_with_last_dates.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758e212f",
   "metadata": {},
   "source": [
    "## Código Para Resolução do Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "909fb4f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T22:55:03.070662Z",
     "start_time": "2024-02-14T22:55:01.739096Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "\n",
    "# Função para converter endereço IP em hash MD5\n",
    "def hash_ip(ip):\n",
    "    return hashlib.md5(ip.encode()).hexdigest()\n",
    "\n",
    "def clean_string(string):\n",
    "    # Remove as aspas extras e os caracteres de escape\n",
    "    cleaned_string = string.strip('\"\\\\')\n",
    "    return cleaned_string\n",
    "# Função para converter a data para formato UNIX timestamp\n",
    "\n",
    "def convert_to_unix_timestamp(date_str):\n",
    "    try:\n",
    "        # Tenta converter a data usando o formato padrão\n",
    "        return datetime.strptime(date_str, \"%d/%b/%Y %H:%M:%S\").timestamp()\n",
    "    except ValueError:\n",
    "        # Tenta ajustar para segundos com apenas um dígito\n",
    "        return datetime.strptime(date_str[:-6] + date_str[-5:], \"%d/%b/%Y %H:%M:%S\").replace(second=int(date_str[-2:])).timestamp()\n",
    "\n",
    "       \n",
    "\n",
    "# Função para ler o arquivo de log e extrair os dados\n",
    "def extract_data_from_log(log_file):\n",
    "    data = []\n",
    "    with open(log_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            remote_host = parts[0]\n",
    "            user_identity = parts[1]\n",
    "            username = parts[2]\n",
    "            date = convert_to_unix_timestamp(parts[3][1:] + ' ' + parts[4][:-1])\n",
    "            request = parts[6] + ' ' + parts[7] + ' ' + parts[8]\n",
    "            status_code = parts[9]\n",
    "            response_time = parts[10]\n",
    "            referer = parts[11]\n",
    "            user_agent = ' '.join(parts[12:])\n",
    "            data.append({\n",
    "                'remote_host': remote_host,\n",
    "                'user_identity': user_identity,\n",
    "                'username': username,\n",
    "                'date': date,\n",
    "                'request': clean_string(request),\n",
    "                'status_code': status_code,\n",
    "                'response_time': response_time,\n",
    "                'referer': clean_string(referer),\n",
    "                'user_agent': clean_string(user_agent)\n",
    "            })\n",
    "    return data\n",
    "\n",
    "def original_extract_data_from_log(log_file):\n",
    "    data = []\n",
    "    with open(log_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            remote_host = parts[0]\n",
    "            user_identity = parts[1]\n",
    "            username = parts[2]\n",
    "            date = parts[3][1:]  # Mantém a data como está\n",
    "            request = ' '.join(parts[6:9])\n",
    "            status_code = parts[9]\n",
    "            response_time = parts[10]\n",
    "            referer = parts[11]\n",
    "            user_agent = ' '.join(parts[12:])\n",
    "            data.append({\n",
    "                'remote_host': remote_host,\n",
    "                'user_identity': user_identity,\n",
    "                'username': username,\n",
    "                'date': date,\n",
    "                'request': clean_string(request),\n",
    "                'status_code': status_code,\n",
    "                'response_time': response_time,\n",
    "                'referer': clean_string(referer),\n",
    "                'user_agent': clean_string(user_agent)\n",
    "            })\n",
    "    return data\n",
    "\n",
    "\n",
    "# Função para escrever dados em formato JSON\n",
    "def write_json(data, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "# Função para encontrar os 10 maiores tempos de resposta com sucesso para a chamada GET /manual/\n",
    "def find_top_10_slowest_requests(data):\n",
    "    filtered_data = [d for d in data if d['status_code'] == '200' and d['referer'] ==  \"http://localhost/svnview?repos=devel&rev=latest&root=SVNview/tmpl&list_revs=1\"]\n",
    "    sorted_data = sorted(filtered_data, key=lambda x: float(x['response_time']), reverse=True)\n",
    "    return sorted_data[:10]\n",
    "\n",
    "# Função para agrupar e contar solicitações por dia do ano.\n",
    "def count_requests_per_day(log_file):\n",
    "    data = original_extract_data_from_log(log_file)\n",
    "    requests_per_day = {}\n",
    "    for d in data:\n",
    "        # Obtém a data no formato 'DD/MM/YYYY'\n",
    "        date = d['date']\n",
    "        if date in requests_per_day:\n",
    "            # Se a data já existe no dicionário, aumente o contador de solicitações para esse dia\n",
    "            requests_per_day[date] += 1\n",
    "        else:\n",
    "            # Se a data ainda não existe no dicionário, adicione-a com um contador de 1\n",
    "            requests_per_day[date] = 1\n",
    "    return requests_per_day\n",
    "\n",
    "\n",
    "\n",
    "# Função para encontrar IPs únicos e suas últimas datas de solicitação.\n",
    "def find_unique_ips_with_last_date(data):\n",
    "    unique_ips = {}\n",
    "    for d in data:\n",
    "        ip = d['remote_host']\n",
    "        date = d['date']\n",
    "        unique_ips[ip] = max(unique_ips.get(ip, 0), date)\n",
    "    return {ip: datetime.utcfromtimestamp(last_date).strftime('%Y-%m-%d %H:%M:%S') for ip, last_date in unique_ips.items()}\n",
    "\n",
    "# Arquivo de log de entrada\n",
    "log_file = 'test-access-001-05-seed-2.log'\n",
    "\n",
    "# Vamos utilizar a função construída e extrair os dados do log\n",
    "data = extract_data_from_log(log_file)\n",
    "\n",
    "# Vamos escrever a saída em formato JSON\n",
    "write_json(data, 'log_data.json')\n",
    "\n",
    "# vamos encontrar os 10 maiores tempos de resposta com sucesso para a chamada GET /manual/\n",
    "top_10_slowest_requests = find_top_10_slowest_requests(data)\n",
    "write_json(top_10_slowest_requests, 'top_10_slowest_requests.json')\n",
    "\n",
    "#Vamos contar solicitações por dia do ano\n",
    "requests_per_day = count_requests_per_day(log_file)\n",
    "write_json(requests_per_day, 'requests_per_day.json')\n",
    "\n",
    "# Vamos encontrar IPs únicos e suas últimas datas de solicitação\n",
    "unique_ips_with_last_date = find_unique_ips_with_last_date(data)\n",
    "with open('unique_ips_with_last_date.txt', 'w') as f:\n",
    "    for ip, last_date in unique_ips_with_last_date.items():\n",
    "        f.write(f'{ip} - Last Date: {last_date}\\n')\n",
    "\n",
    "# Vamos escrever o log formatado com a data em formato UNIX timestamp e IP convertido em hash MD5\n",
    "with open('formatted_access.log', 'w') as f:\n",
    "    for d in data:\n",
    "        formatted_date = datetime.utcfromtimestamp(d['date']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        formatted_ip = hash_ip(d['remote_host'])\n",
    "        f.write(f\"{formatted_ip} - - [{formatted_date}] \\\"{d['request']}\\\" {d['status_code']} {d['response_time']} \\\"{d['referer']}\\\" \\\"{d['user_agent']}\\\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
